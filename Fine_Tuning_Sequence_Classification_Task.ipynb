{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44355837-f393-41f6-9bcc-bec7129f8bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857b9b0-2fa0-4d20-9e18-87b903d91a06",
   "metadata": {},
   "source": [
    "Load data from HF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2622b236-f551-4541-bb3e-d4731d54e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"yahoo_answers_topics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e57604d-b896-4eb0-9e30-4c936a18c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0038c341-7f29-48c4-823c-8dd27e8a2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'].features['topic'].int2str(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "159322eb-55c6-43ec-b8df-e015a35ed04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = dataset['train'].unique('topic')\n",
    "label_list.sort()\n",
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "badaf5a9-0696-4dbb-9b9d-a20f701a379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_list)\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c6f706d-9f01-414b-a734-e7032562858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = dataset.rename_column('topic', 'labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ba5c0-5815-485c-b8b3-63a5305d79f2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989404c2-d856-43f1-abdf-98b21f4c4cbe",
   "metadata": {},
   "source": [
    "Tokenizer essentially parses and converts the data. The tokenizer class contains the Vocabulary as well\n",
    "Models have their custom tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1eb271a-befc-4d9a-9425-b0375836856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9890590-40b3-4a61-921a-3a831ce9e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = dataset['train'][0]['question_title']\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d80c5f19-0e36-4b43-b8d2-567d036f374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: tokenizer(x['question_title'], truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "970a9399-9048-427a-a835-74ceb8b2d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "25c0a586-9682-4b5c-bf8b-fa98e2842d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7fddaec-6033-4d99-ba74-c0b9ed364b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_topic(sentence, tokenize=tokenizer, model=model):\n",
    "    # tokenize the input\n",
    "    inputs = tokenizer(sentence, return_tensors='pt')\n",
    "    # ensure model and inputs are on the same device (GPU)\n",
    "    inputs = {name: tensor.cuda() for name, tensor in inputs.items()}\n",
    "    model = model.cuda()\n",
    "    # get prediction - 10 classes \"probabilities\" (not really true because they still need to be normalized)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(**inputs)[0].cpu().numpy()\n",
    "    # get the top prediction class and convert it to its associated label\n",
    "    top_prediction = predictions.argmax().item()\n",
    "    return dataset['train'].features['labels'].int2str(top_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5379ce69-8bcd-4834-9461-de8aa83f6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic('Why is cheese so much better with wine?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6758fb99-8047-4e20-9d73-ec3fcdf933d7",
   "metadata": {},
   "source": [
    "We use the trainer module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ae66cc0-397f-4611-ad53-59f3661cf680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    report_to = 'wandb',                     # enable logging to W&B\n",
    "    output_dir = 'topic_classification',    # output directory\n",
    "    overwrite_output_dir = True,\n",
    "    evaluation_strategy = 'steps',          # check evaluation metrics at each epoch\n",
    "    learning_rate = 5e-5,                   # we can customize learning rate\n",
    "    max_steps = 3000,\n",
    "    logging_steps = 100,                    # we will log every 100 steps\n",
    "    eval_steps = 500,                      # we will perform evaluation every 500 steps\n",
    "    save_steps = 1000,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'accuracy',\n",
    "    run_name = 'custom_training'            # name of the W&B run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc37ad52-4517-4fe3-8696-903cd3b7ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    # metrics from the datasets library have a `compute` method\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94a48b28-c7e8-49b6-8939-780b12e6c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,                  # model to be trained\n",
    "    args = args,                    # training args\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    tokenizer=tokenizer,            # for padding batched data\n",
    "    compute_metrics=compute_metrics # for custom metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e4f65d4-c2bc-4688-9215-1d42d0c75012",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf9d74ad-3219-479b-833a-3bdc939490b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82133815-11b8-44f2-85a3-800616cc5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_topic('Why is cheese so much better with wine?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9ffdbd6-f72a-4e97-b77c-582aaad30090",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c504111-7976-4119-ab26-4c4ed34760bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
